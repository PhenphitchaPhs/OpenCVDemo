<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion AI - Cutie Version</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Mali:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --cute-pink: #ffafbd;
            --cute-peach: #ffc3a0;
            --main-font: 'Mali', cursive;
        }

        body { 
            font-family: var(--main-font); 
            background: linear-gradient(135deg, #fdfbfb 0%, #ebedee 100%); 
            color: #5d5d5d; 
            margin: 0; 
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            overflow: hidden;
        }

        /* ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å */
        body::before {
            content: "‚òÅÔ∏è"; position: absolute; top: 10%; left: 10%; font-size: 50px; opacity: 0.3;
        }
        body::after {
            content: "‚ú®"; position: absolute; bottom: 15%; right: 15%; font-size: 40px; opacity: 0.3;
        }

        #status { 
            background: rgba(255, 255, 255, 0.8);
            padding: 12px 25px; 
            color: #ff8a9a; 
            font-weight: 700; 
            border-radius: 30px;
            border: 2px solid var(--cute-pink);
            margin-bottom: 20px;
            box-shadow: 0 8px 20px rgba(255, 175, 189, 0.3);
            font-size: 16px;
            z-index: 10;
        }

        .main-wrapper {
            position: relative;
            padding: 15px;
            background: white;
            border-radius: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            border: 6px solid #fff;
        }

        canvas { 
            border-radius: 30px; 
            display: block;
            width: 100%;
            max-width: 640px;
            background: #eee;
        }

        .info-panel {
            margin-top: 20px;
            font-size: 14px;
            color: #aaa;
            background: #fff;
            padding: 5px 15px;
            border-radius: 20px;
        }
    </style>

    <script>
        let session;
        let faceCascade;
        // ‡∏õ‡∏£‡∏±‡∏ö Label ‡πÉ‡∏´‡πâ‡∏°‡∏µ Emoji ‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤
        const labels = ["üò° Angry", "ü§¢ Disgust", "üò® Fear", "üòä Happy", "üò¢ Sad", "üò≤ Surprise", "üòê Neutral"]; 

        async function onOpenCvReady() {
            const status = document.getElementById('status');
            status.innerText = "‡∏£‡∏≠‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î AI... üéÄ";
            try {
                session = await ort.InferenceSession.create('./emotion_yolo11n_cls.onnx');
                
                faceCascade = new cv.CascadeClassifier();
                const faceXml = 'haarcascade_frontalface_default.xml';
                const res = await fetch(faceXml);
                const buffer = await res.arrayBuffer();
                cv.FS_createDataFile("/", faceXml, new Uint8Array(buffer), true, false, false);
                faceCascade.load(faceXml);

                status.innerText = "‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞! ‡∏°‡∏≤‡∏¢‡∏¥‡πâ‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞ ‚ú®";
                startVideo();
            } catch (e) {
                status.innerText = "‡∏≠‡∏∏‡πä‡∏¢! ‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î";
                console.error(e);
            }
        }

        function startVideo() {
            const video = document.getElementById('videoInput');
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                video.onloadedmetadata = () => { processVideo(); };
            });
        }

        async function processVideo() {
            const video = document.getElementById('videoInput');
            const canvas = document.getElementById('canvasOutput');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            
            if (video.paused || video.ended) return;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            let src = cv.imread(canvas);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            let faces = new cv.RectVector();
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                
                // ‡∏Å‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏µ‡∏ä‡∏°‡∏û‡∏π‡∏û‡∏≤‡∏™‡πÄ‡∏ó‡∏•‡πÅ‡∏ö‡∏ö‡∏°‡∏ô‡πÜ
                ctx.strokeStyle = "#ffafbd";
                ctx.lineWidth = 5;
                ctx.lineJoin = "round";
                ctx.strokeRect(face.x, face.y, face.width, face.height);

                try {
                    const size = 128; 
                    const faceCanvas = document.createElement('canvas');
                    faceCanvas.width = size; faceCanvas.height = size;
                    const fCtx = faceCanvas.getContext('2d');
                    fCtx.drawImage(canvas, face.x, face.y, face.width, face.height, 0, 0, size, size);
                    
                    const imgData = fCtx.getImageData(0, 0, size, size);
                    const input = new Float32Array(1 * 3 * size * size);
                    for (let c = 0; c < 3; c++) {
                        for (let p = 0; p < size * size; p++) {
                            input[c * size * size + p] = imgData.data[p * 4 + c] / 255.0;
                        }
                    }

                    const tensor = new ort.Tensor('float32', input, [1, 3, size, size]);
                    const output = await session.run({ [session.inputNames[0]]: tensor });
                    const outputData = output[session.outputNames[0]].data;
                    
                    const maxIdx = outputData.indexOf(Math.max(...outputData));
                    const emotion = labels[maxIdx] || "???";

                    // ‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡πÇ‡∏Ñ‡πâ‡∏á‡∏°‡∏ô‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å
                    ctx.fillStyle = "#ffafbd";
                    const textWidth = ctx.measureText(emotion).width;
                    
                    // ‡∏ß‡∏≤‡∏î‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏ö‡∏°‡∏ô (Rounded Rect)
                    const r = 15; // ‡∏£‡∏±‡∏®‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏ô
                    const x = face.x; const y = face.y - 55; const w = textWidth + 60; const h = 40;
                    ctx.beginPath();
                    ctx.moveTo(x + r, y);
                    ctx.arcTo(x+w, y, x+w, y+h, r);
                    ctx.arcTo(x+w, y+h, x, y+h, r);
                    ctx.arcTo(x, y+h, x, y, r);
                    ctx.arcTo(x, y, x+w, y, r);
                    ctx.closePath();
                    ctx.fill();

                    ctx.fillStyle = "#fff";
                    ctx.font = "bold 22px Mali";
                    ctx.fillText(emotion, face.x + 15, face.y - 27);

                } catch (err) { console.error(err); }
            }
            src.delete(); gray.delete(); faces.delete();
            requestAnimationFrame(processVideo);
        }
    </script>
    <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
</head>
<body>

    <div id="status">‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏•‡∏∏‡∏Å AI ‡πÉ‡∏´‡πâ‡∏ï‡∏∑‡πà‡∏ô... ‚òÅÔ∏è</div>

    <div class="main-wrapper">
        <video id="videoInput" width="640" height="480" autoplay playsinline style="display:none;"></video>
        <canvas id="canvasOutput" width="640" height="480"></canvas>
    </div>

    <div class="info-panel">Emotion AI Dashboard ‚ô° v2.0</div>

</body>
</html>
