<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Emotion Detection - Real Time</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
    <style>
        body { font-family: sans-serif; text-align: center; background: #000; color: #fff; margin: 0; }
        .container { position: relative; display: inline-block; margin-top: 20px; }
        canvas { border: 2px solid #333; border-radius: 10px; width: 100%; max-width: 640px; }
        #status { background: #222; padding: 10px; color: #00ff00; font-weight: bold; }
    </style>
</head>
<body>
    <div id="status">กำลังรอระบบ...</div>
    <div class="container">
        <video id="videoInput" width="640" height="480" autoplay playsinline style="display:none;"></video>
        <canvas id="canvasOutput" width="640" height="480"></canvas>
    </div>

    <script>
        let session;
        let faceCascade;
        // ลำดับอารมณ์ต้องตรงกับที่เทรน (ส่วนใหญ่คือ: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral)
        const labels = ["Angry", "Disgust", "Fear", "Happy", "Sad", "Surprise", "Neutral"]; 

        async function onOpenCvReady() {
            const status = document.getElementById('status');
            status.innerText = "กำลังโหลดโมเดล AI...";
            try {
                session = await ort.InferenceSession.create('./emotion_yolo11n_cls.onnx');
                faceCascade = new cv.CascadeClassifier();
                const faceXml = 'haarcascade_frontalface_default.xml';
                const res = await fetch(faceXml);
                const buffer = await res.arrayBuffer();
                cv.FS_createDataFile("/", faceXml, new Uint8Array(buffer), true, false, false);
                faceCascade.load(faceXml);
                status.innerText = "AI พร้อมทำงาน! กรุณายิ้มให้กล้อง";
                startVideo();
            } catch (e) {
                status.innerText = "Error: " + e.message;
            }
        }

        function startVideo() {
            const video = document.getElementById('videoInput');
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                video.onloadedmetadata = () => { processVideo(); };
            });
        }

        async function processVideo() {
            const video = document.getElementById('videoInput');
            const canvas = document.getElementById('canvasOutput');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            if (video.paused || video.ended) return;

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            let src = cv.imread(canvas);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            let faces = new cv.RectVector();
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                ctx.strokeStyle = "#00ff00";
                ctx.lineWidth = 4;
                ctx.strokeRect(face.x, face.y, face.width, face.height);

                // --- ส่วนที่เพิ่ม: การดึงอารมณ์จากโมเดล ---
                try {
                    // 1. ตัดภาพเฉพาะใบหน้าและ Resize เป็น 64x64 (หรือ 128 ตามที่เทรน)
                    const size = 64; 
                    let faceRegion = src.roi(face);
                    let resizedFace = new cv.Mat();
                    cv.resize(faceRegion, resizedFace, new cv.Size(size, size));

                    // 2. แปลงเป็น Tensor (RGB)
                    const input = new Float32Array(1 * 3 * size * size);
                    for (let c = 0; c < 3; c++) {
                        for (let h = 0; h < size; h++) {
                            for (let w = 0; w < size; w++) {
                                // ดึงค่าสีและ Normalization (0-1)
                                input[c * size * size + h * size + w] = resizedFace.data[(h * size + w) * 4 + c] / 255.0;
                            }
                        }
                    }
                    const tensor = new ort.Tensor('float32', input, [1, 3, size, size]);

                    // 3. รันโมเดล
                    const output = await session.run({ images: tensor });
                    const outputData = output[Object.keys(output)[0]].data;
                    const maxIdx = outputData.indexOf(Math.max(...outputData));
                    const emotion = labels[maxIdx];

                    // 4. แสดงผลอารมณ์บนหน้าจอ
                    ctx.fillStyle = "#00ff00";
                    ctx.font = "bold 30px Arial";
                    ctx.fillText(emotion, face.x, face.y - 15);

                    faceRegion.delete(); resizedFace.delete();
                } catch (err) {
                    console.error("Inference error:", err);
                }
            }
            src.delete(); gray.delete(); faces.delete();
            requestAnimationFrame(processVideo);
        }
    </script>
</body>
</html>
