<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Emotion Detection - Final Fix</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
    <style>
        body { font-family: sans-serif; text-align: center; background: #000; color: #fff; margin: 0; }
        .container { position: relative; display: inline-block; margin-top: 20px; }
        canvas { border: 2px solid #333; border-radius: 10px; width: 100%; max-width: 640px; }
        #status { background: #222; padding: 10px; color: #00ff00; font-weight: bold; }
    </style>
</head>
<body>
    <div id="status">กำลังรอ OpenCV...</div>
    <div class="container">
        <video id="videoInput" width="640" height="480" autoplay playsinline style="display:none;"></video>
        <canvas id="canvasOutput" width="640" height="480"></canvas>
    </div>

    <script>
        let session;
        let faceCascade;
        // ลำดับอารมณ์จาก classes.json ของคุณ
        const labels = ["Angry", "Disgust", "Fear", "Happy", "Sad", "Surprise", "Neutral"]; 

        async function onOpenCvReady() {
            const status = document.getElementById('status');
            try {
                // 1. โหลดโมเดล
                session = await ort.InferenceSession.create('./emotion_yolo11n_cls.onnx');
                
                // 2. โหลดตัวตรวจจับใบหน้า
                faceCascade = new cv.CascadeClassifier();
                const faceXml = 'haarcascade_frontalface_default.xml';
                const res = await fetch(faceXml);
                const buffer = await res.arrayBuffer();
                cv.FS_createDataFile("/", faceXml, new Uint8Array(buffer), true, false, false);
                faceCascade.load(faceXml);

                status.innerText = "ระบบออนไลน์! ลองยิ้มดูครับ";
                startVideo();
            } catch (e) {
                status.innerText = "Error: " + e.message;
            }
        }

        function startVideo() {
            const video = document.getElementById('videoInput');
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                video.onloadedmetadata = () => { processVideo(); };
            });
        }

        async function processVideo() {
            const video = document.getElementById('videoInput');
            const canvas = document.getElementById('canvasOutput');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            if (video.paused || video.ended) return;

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            let src = cv.imread(canvas);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            let faces = new cv.RectVector();
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                ctx.strokeStyle = "#00ff00";
                ctx.lineWidth = 4;
                ctx.strokeRect(face.x, face.y, face.width, face.height);

                try {
                    const size = 64; // ถ้าเทรนมา imgsz=128 ให้เปลี่ยนเป็น 128 ครับ
                    
                    // ตัดภาพหน้าและเตรียม Tensor
                    const faceCanvas = document.createElement('canvas');
                    faceCanvas.width = size;
                    faceCanvas.height = size;
                    const fCtx = faceCanvas.getContext('2d');
                    fCtx.drawImage(canvas, face.x, face.y, face.width, face.height, 0, 0, size, size);
                    
                    const imgData = fCtx.getImageData(0, 0, size, size);
                    const input = new Float32Array(1 * 3 * size * size);
                    
                    // ปรับรูปแบบข้อมูลให้ตรงกับ YOLO (NCHW)
                    for (let c = 0; c < 3; c++) {
                        for (let p = 0; p < size * size; p++) {
                            input[c * size * size + p] = imgData.data[p * 4 + c] / 255.0;
                        }
                    }

                    const tensor = new ort.Tensor('float32', input, [1, 3, size, size]);
                    
                    // รันโมเดลและดึงผลลัพธ์จาก Output Node แรกที่เจอ
                    const feeds = {};
                    feeds[session.inputNames[0]] = tensor;
                    const output = await session.run(feeds);
                    const outputData = output[session.outputNames[0]].data;
                    
                    // หาค่าที่สูงสุด (อารมณ์ที่มั่นใจที่สุด)
                    const maxIdx = outputData.indexOf(Math.max(...outputData));
                    const emotion = labels[maxIdx] || "Unknown";

                    ctx.fillStyle = "#00ff00";
                    ctx.font = "bold 32px Arial";
                    ctx.fillText(emotion, face.x, face.y - 15);
                } catch (err) {
                    console.error(err);
                }
            }
            src.delete(); gray.delete(); faces.delete();
            requestAnimationFrame(processVideo);
        }
    </script>
</body>
</html>
