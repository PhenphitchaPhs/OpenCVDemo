<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Emotion Detection Real-time</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="./opencv.js"></script>
    <style>
        body { font-family: sans-serif; text-align: center; background: #1a1a1a; color: white; }
        canvas { border: 4px solid #333; border-radius: 10px; max-width: 100%; }
        #status { color: #00ff00; font-size: 1.2em; margin: 10px; }
    </style>
</head>
<body>
    <h1>AI Emotion Detection</h1>
    <p id="status">กำลังโหลดระบบ... (กรุณารอแถบสีเขียว)</p>
    <video id="videoInput" width="640" height="480" autoplay playsinline style="display:none;"></video>
    <canvas id="canvasOutput" width="640" height="480"></canvas>

    <script>
        let session;
        let labels = [];
        let faceCascade;

        async function init() {
            const status = document.getElementById('status');
            try {
                // 1. โหลด Labels
                const res = await fetch('./classes.json');
                const labelData = await res.json();
                labels = Object.values(labelData);

                // 2. โหลดโมเดล ONNX
                session = await ort.InferenceSession.create('./emotion_yolo11n_cls.onnx');

                // 3. เตรียม OpenCV Face Detector
                faceCascade = new cv.CascadeClassifier();
                const faceXml = 'haarcascade_frontalface_default.xml';
                
                // โหลดไฟล์ XML เข้าสู่ระบบจำลองของ OpenCV
                const response = await fetch(faceXml);
                const buffer = await response.arrayBuffer();
                cv.FS_createDataFile("/", faceXml, new Uint8Array(buffer), true, false, false);
                faceCascade.load(faceXml);

                status.innerText = "ระบบพร้อมใช้งาน! ส่องหน้าได้เลย";
                startVideo();
            } catch (e) {
                status.innerText = "Error: " + e.message;
                console.error(e);
            }
        }

        function startVideo() {
            const video = document.getElementById('videoInput');
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                processFrame();
            });
        }

        async function processFrame() {
            const video = document.getElementById('videoInput');
            const canvas = document.getElementById('canvasOutput');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });

            if (video.paused || video.ended) return;

            // วาดภาพสดจากกล้อง
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            let src = cv.imread(canvas);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            let faces = new cv.RectVector();

            // ตรวจจับใบหน้า
            faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                
                // วาดกรอบสี่เหลี่ยมรอบหน้า
                ctx.strokeStyle = "#00FF00";
                ctx.lineWidth = 3;
                ctx.strokeRect(face.x, face.y, face.width, face.height);

                // เตรียมภาพใบหน้าส่งให้ AI (Resize เป็น 128x128 ตามที่ตั้งค่าในตอนเทรน)
                const faceCanvas = document.createElement('canvas');
                faceCanvas.width = 128; // ปรับตาม imgsz ที่คุณใช้เทรน (64 หรือ 128)
                faceCanvas.height = 128;
                const faceCtx = faceCanvas.getContext('2d');
                faceCtx.drawImage(canvas, face.x, face.y, face.width, face.height, 0, 0, 128, 128);

                // แปลงภาพเป็น Tensor เพื่อส่งให้โมเดล .onnx
                const imageData = faceCtx.getImageData(0, 0, 128, 128);
                const input = new Float32Array(1 * 3 * 128 * 128);
                for (let j = 0; j < imageData.data.length / 4; j++) {
                    input[j] = imageData.data[j * 4] / 255;           // R
                    input[j + 128*128] = imageData.data[j * 4 + 1] / 255;   // G
                    input[j + 2*128*128] = imageData.data[j * 4 + 2] / 255; // B
                }
                const tensor = new ort.Tensor('float32', input, [1, 3, 128, 128]);

                // รันโมเดลทายอารมณ์
                const output = await session.run({ "images": tensor });
                const results = Array.from(output[Object.keys(output)[0]].data);
                const maxIdx = results.indexOf(Math.max(...results));
                const emotion = labels[maxIdx];

                // เขียนข้อความบอกอารมณ์บนหัว
                ctx.fillStyle = "#00FF00";
                ctx.font = "bold 24px Arial";
                ctx.fillText(emotion, face.x, face.y - 10);
            }

            src.delete(); gray.delete(); faces.delete();
            requestAnimationFrame(processFrame);
        }

        // เริ่มเมื่อ OpenCV พร้อม
        if (cv.RuntimeInitialized) { init(); } 
        else { cv.onRuntimeInitialized = init; }
    </script>
</body>
</html>
